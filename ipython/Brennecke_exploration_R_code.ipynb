{
 "metadata": {
  "name": "",
  "signature": "sha256:2406c7e73dd9865e0db687d3225d98374fe08f328103049f31120bbf28fba8b6"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Note that rmagic is currently not working, but eventually this notebook will be used instead of forcefeeding into R manually."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!ls /home/kunal/workspace/single-cell/data/brennecke"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "nmeth.2645-S10.csv   nmeth.2645-S11.xlsx\r\n",
        "nmeth.2645-S10.xlsx  nmeth.2645-S7.xlsx\r\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Load Libraries\n",
      "library( DESeq )\n",
      "library( genefilter )\n",
      "library( EBImage )\n",
      "library( statmod )\n",
      "options( max.print=300, width=100 )\n",
      "\n",
      "# I converted the xlsx to csv for further use\n",
      "supp8 <- \"/home/kunal/workspace/single-cell/data/brennecke/nmeth.2645-S10.csv\"\n",
      "fullCountTable <- read.csv( supp8, header=TRUE, row.names=1 )\n",
      "head( fullCountTable )\n",
      "\n",
      "#We subset the count table to only the columns referring to GL2 cells and clean up the column names.\n",
      "countsAll <- fullCountTable[, substr( colnames(fullCountTable), 1, 3 ) == \"GL2\" ]\n",
      "colnames(countsAll) <- gsub( \"\\\\.\", \"-\", colnames(countsAll) )\n",
      "\n",
      "#We split the count table in three sub-tables, one for the A. thalina plant genes (\"At\"), one for the HeLa genes (\"HeLa\") and one for the IVT spikes (\"Sp\"). The first two letter of the gene IDs (row names) are used for this categorization\n",
      "geneTypes <- factor( c( AT=\"At\", pG=\"pGIBS\", EN=\"HeLa\", ER=\"ERCC\" )[\n",
      "substr( rownames(countsAll), 1, 2 ) ] )\n",
      "countsHeLa <- countsAll[ which( geneTypes==\"HeLa\" ), ]\n",
      "countsAt <- countsAll[ which( geneTypes==\"At\" ), ]\n",
      "countsSp <- countsAll[ which( geneTypes %in% c( \"pGIBS\", \"ERCC\" ) ), ]\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "So at this point, the data is ready to be used for analysis. First, they calculate the size factors to determine a normalization factor for technical noise (based on HeLa factors) and biological noise (based on plant gene counts \"At\")"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<b>The size factors are meant to provide a scaling normalization i.e. dividing the counts by the appropriate size factors bring them onto a common scale that allows comparison across samples\n",
      "\n",
      "s_j for technical genes is simply an estimate of relative sequencing depth\n",
      "\n",
      "biological however differs from sample to sample due to efficiency of cell lysis and differences in cell size and total RNA content of each cell.</b>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To normalize the read counts, we used the method that we\n",
      "developed for DESeq19 (see also Supplementary Note 6). Briefly,\n",
      "for each gene, i, we calculate the geometric mean:\n",
      "\\begin{equation}\n",
      "k_{i}^M = (\\prod_{j=1}^{m}k_{ij})^{1/m}\n",
      "\\end{equation}\n",
      "over the counts $k_{ij}$ across all samples $j=1,...,m$ and then use, for each sample, the median of the ratio of the sample's counts to these means as a 'size factor':\n",
      "\\begin{equation}\n",
      "s_j = \\text{median}_i(k_ij/k_{i}^M)\n",
      "\\end{equation}\n",
      "In other words, find a ratio for sample j that allows comparisons across all samples by finding a gene i in sample j that has the median ratio.\n",
      "**Note: surprised they don't use any variance term here. Should read DESeq2 paper."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Estimate technical and biological size factors\n",
      "sfHeLa <- estimateSizeFactorsForMatrix( countsHeLa )\n",
      "sfAt <- estimateSizeFactorsForMatrix( countsAt)\n",
      "rbind( HeLa = sfHeLa, At = sfAt, ratio = sfAt / sfHeLa )"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "HeLa  0.5173383 2.022511 2.8804054 0.8552699 2.0415875 0.9551039 0.3109511\n",
      "At    1.0234077 1.933931 1.7603544 1.3696320 0.8933595 0.8634580 0.5341586\n",
      "ratio 1.9782176 0.956203 0.6111481 1.6014033 0.4375808 0.9040461 1.7178219\n",
      "\n",
      "This indicates that there is high variability between just technical and biological noise. Although it would be interesting to observe this difference between the ERCC spikeins and some house keeping genes and see their ratios."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Normalize the counts\n",
      "nCountsHeLa <- t( t(countsHeLa) / sfHeLa )\n",
      "nCountsAt <- t( t(countsAt) / sfAt )\n",
      "\n",
      "# Create scatter plots showing the correlation of normalized counts between the different samples.\n",
      "colHeLa <- \"blue\"\n",
      "colAt <- \"red\"\n",
      "colAtHi <- \"yellow\"\n",
      "pairs( log10( .1 + rbind( nCountsAt, nCountsHeLa ) ), pch=19, cex=.2,\n",
      "col = c( rep( colAt, nrow(nCountsAt) ), rep( colHeLa, nrow(nCountsHeLa) ) ) )\n",
      "\n",
      "# Pretty plotter function\n",
      "geneScatterplot <- function( x, y, xlab, ylab, col ) {\n",
      "plot( NULL, xlim=c( -.1, 6.2 ), ylim=c( -1, 6.2 ),\n",
      "xaxt=\"n\", yaxt=\"n\", xaxs=\"i\", yaxs=\"i\", asp=1,\n",
      "xlab=xlab, ylab=ylab )\n",
      "abline( a=-1, b=1, col = \"lightgray\", lwd=2 )\n",
      "abline( a=0, b=1, col = \"lightgray\", lwd=2 )\n",
      "abline( a=1, b=1, col = \"lightgray\", lwd=2 )\n",
      "abline( h=c(0,2,4,6), v=c(0,2,4,6), col = \"lightgray\", lwd=2 )\n",
      "points(\n",
      "ifelse( x > 0, log10(x), -.7 ),\n",
      "ifelse( y > 0, log10(y), -.7 ),\n",
      "pch=19, cex=.2, col = col )\n",
      "axis( 1, c( -.7, 0:6 ),\n",
      "c( \"0\", \"1\", \"10\", \"100\", expression(10^3), expression(10^4),\n",
      "expression(10^5), expression(10^6) ) )\n",
      "axis( 2, c( -.7, 0:6 ),\n",
      "c( \"0\", \"1\", \"10\", \"100\", expression(10^3), expression(10^4),\n",
      "expression(10^5), expression(10^6) ), las=2 )\n",
      "axis( 1, -.35, \"//\", tick=FALSE, line=-.7 )\n",
      "axis( 2, -.35, \"\\\\\\\\\", tick=FALSE, line=-.7 )\n",
      "}\n",
      "\n",
      "#Create plots for figure 2a and 2b\n",
      "geneScatterplot( nCountsHeLa[,1], nCountsHeLa[,3],\n",
      "\"normalized read count, GL2 cell 1\", \"normalized read count, GL2 cell 3\",\n",
      "colHeLa )\n",
      "geneScatterplot( nCountsAt[,1], nCountsAt[,3],\n",
      "\"normalized read count, GL2 cell 1\", \"normalized read count, GL2 cell 3\",\n",
      "colAt )\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "I'm going to skip the part about seeing if transcript length should be use as well for normalization for now. "
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Main model"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Goal: quantify the amount of variation present from the technical RNA and compare this to the biological variation. I.E. Find the amount of biological variation that can be xplained away by the technical variation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let $K_{ij}$ denote the number of reads mapped to technical gene $i$ from sample $j$ and $K_{ij}^{B}$ is the read count for biological gene $i$.\n",
      "\n",
      "<b> TECHNICAL NOISE </b>\n",
      "\n",
      "Key assumptions about technical data:\n",
      "\n",
      "1. Expected ratios of transcript concentrations are the same in all samples since the aliquots come from the same bulk RNA sample\n",
      "\n",
      "2. The absolute amount of \"technical RNA\" present in each sample is the same since a fixed aliquot volume is pipetted into each sample\n",
      "(1. follows from 2., but w/e)\n",
      "\n",
      "Let $\\mu_{i}$ be a measure of abundance of transcripts from gene $i$ in the initial bulk mix of technical RNA. However, there are sampling effects caused by diluting and aliquoting and variations in sequence-specific efficiencies of preparing the library $j$, as such the actual concentration of the transcript fragments is $Q_{ij}$ for gene $i$ in library $j$, but the $E(Q_{ij}) = \\mu_i$\n",
      "\n",
      "<b>Another way to look at this is that all sequence specific effects biases affecting the number of reads gained from a transcript molecule that do not vary from sample to sample are considered absorbed in $\\mu_{i}$ TODO: fully comprehend this sentence.</b>\n",
      "\n",
      "The variance of $Q_{ij}$ tells you how much noise there is surrounding the measurement of gene $i$. They postulate that this variance is determined by mainly the mean $\\mu_i$, indicating that this variance is heavily influenced by the number of transcript available.\n",
      "\\begin{equation}\n",
      "Var(Q_{ij}) = \\widetilde{a}\\mu_{i} + \\alpha_{0}\\mu_{i}^{2}.\n",
      "\\end{equation}\n",
      "\n",
      "Then to get back to the amount of reads for each gene $i$ in sample $j$, $K_{ij}$, you can put it in terms of the concentration of the gene $i$ in library $j$\n",
      "\n",
      "\\begin{equation}\n",
      "K_{ij}|Q_{ij} \\text{~} Pois(s_jQ_{ij})\n",
      "\\end{equation}\n",
      "\n",
      "Then if you marginalize over $Q_ij$ by plugging in its expected value\n",
      "\\begin{equation}\n",
      "E(K_{ij}) = s_j\\mu_i\n",
      "\\end{equation}\n",
      "\\begin{equation}\n",
      "Var(K_{ij}) = s_j(1+s_j\\widetilde{a}_1)\\mu_i + s_j^2\\alpha_0\\mu_i^2.\n",
      "\\end{equation}\n",
      "\n",
      "$s_j$ is calculated as before, the calculation of the factors $\\widetilde{a}_1$ and $\\alpha_0$ is as follows. First, they calculate the mean and variance of the normalized counts $K_{ij}/s_j$ \n",
      "\n",
      "\\begin{equation}\n",
      "\\hat{\\mu_i} = \\dfrac{1}{m}\\sum_{j=1}^{m}{\\dfrac{K_{ij}}{s_j}}\n",
      "\\end{equation}\n",
      "and the variance\n",
      "\\begin{equation}\n",
      "\\hat{W_i} = \\dfrac{1}{m-1}\\sum_{j=1}^{m}{(\\dfrac{K_{ij}}{s_j} - \\hat{\\mu_i})}^2.\n",
      "\\end{equation}\n",
      "\n",
      "If you use the previous expectations for the $K_{ij}$ mean and variance, it follows that \n",
      "\n",
      "\\begin{equation}\n",
      "E(\\hat{W_i}) = (\\Xi + \\widetilde{a}_1)\\mu_i + \\alpha_0\\mu_i^2 \\text{ with } \\Xi = \\dfrac{1}{m}\\sum_{j=1}^{m}{\\dfrac{1}{s_j}}\n",
      "\\end{equation}\n",
      "\n",
      "Since the value of $\\mu_i$ is not known, the regression will happen on $\\hat{mu}_i$, they put $E(\\hat{W}_i)$ in terms of $\\hat{\\mu}_i$. They use the calculation of variance and mean of $K_{ij}$ to do this. I was not able to immediately replicate this on paper and pencil, but will take their word for it.\n",
      "\n",
      "\\begin{equation}\n",
      "E(\\hat{\\mu_i^2}) = \\mu_i^2(1+\\dfrac{\\alpha_0}{m}) + \\mu_i\\dfrac{\\Xi + \\widetilde{a}_1}{m}\n",
      "\\end{equation}\n",
      "\n",
      "Then the expected value for the variance of the normalized read counts $K_{ij}/s_j$ becomes\n",
      "\\begin{equation}\n",
      "E(\\hat{W_i}) = \\dfrac{1}{1+\\dfrac{\\alpha_0}{m}}E[(\\Xi + \\alpha_1)+\\hat{\\mu_i} + \\alpha_0\\hat{\\mu}_i^2]\n",
      "\\end{equation}\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}